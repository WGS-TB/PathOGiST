#!/usr/bin/env python3
import os
import sys
import subprocess
import resource
import argparse
import logging
import numpy
import itertools
import re
import collections
import pkg_resources
import shutil
import yaml

import pathogist
import pathogist.cluster
import pathogist.io
import pathogist.distance
import pathogist.visualize

logger = logging.getLogger()

#def run_snippy(forward, reverse, reference, threads, map_qual,min_cov, min_frac, rgid, bwaopt):
def run_snippy(snippy_command,snippy_options,temp):
    forward = snippy_options['pe1']
    sample = re.sub("_1.fastq.gz", "", re.sub(".*/","",forward)) #obtain sample name of read
    #cwd = os.getcwd() #obtain cwd
    #outdir=cwd + "/tmp/" + sample #save files in a tmp direction under cwd
    outdir= temp + '/' + sample #save files in a tmp direction under cwd
    '''
    subprocess.run(["snippy", "--force", "--cleanup", "--cpus", str(threads),
                    "--mapqual", str(map_qual), "--mincov", str(min_cov),
                    "--minfrac", str(min_frac), "--rgid", rgid, "--bwaopt", bwaopt, 
                    "--outdir", outdir, "--reference", reference, 
                    "--pe1", forward, "--pe2", reverse])
    '''
    subprocess.run(snippy_command)
    # filter vcf to obtain only entries with non complex variants
    with open( outdir+"/snps.vcf" ) as f: # non_complex_vcf input
        with open( outdir+"/non_complex_snps.vcf", 'w') as g: # non_complex_vcf_output
            for line in f:
                entries = line.rstrip().split('\t')
                if len(entries) == 1: # keep header of vcf file
                    g.write(line)
                else:
                    if len(entries[3]) == len(entries[4]): # keep entries with only same length ref(3) and alt(4) alleles
                        g.write(line)
    primitive_vcf = open( outdir+"/snps.primitive.vcf", "w")
    subprocess.run(["vcfallelicprimitives", "-kg", outdir+"/non_complex_snps.vcf" ], 
                   stdout = primitive_vcf, env = vcflib_env)
    primitive_tab = open(outdir+"/snps.primitive.tab", "w")
    primitive_tab.write(sample+"\n") #append sample to beginning of primitive_tab
    primitive_tab = open(outdir+"/snps.primitive.tab", "a")
    #append rest of the tab file to primitive_tab
    subprocess.run(["snippy-vcf_to_tab", "--gff", outdir + "/reference/ref.gff", "--ref", outdir + "/reference/ref.fa", 
                    "--vcf", outdir+"/snps.primitive.vcf"],
                   stdout = primitive_tab)
    # next iteration remove files we dont need?
    return outdir+"/snps.primitive.tab" # return the path to tab file used for pathogist distance function


def run_all(param):
    '''
    Run the entire PathOGiST pipeline from distance matrix creation to consensus clustering, or create
    a new configuration file.
    '''
    if param.new_config:
        # Copy the default configuration file to whereever the user has specified
        src_path = pkg_resources.resource_filename(__name__,'pathogist/resources/blank_config.yaml') 
        shutil.copyfile(src_path,param.config) 
        print("New configuration file written at %s" % param.config)
    else:
        with open(param.config,'r') as config_stream:
            try:
                config = yaml.load(config_stream) 
            except yaml.YAMLError:
                print(yaml.YAMLError)
                sys.exit(1)

        # Determine whether to save temporary files, and which directory to do so
        temp_dir = config['temp'].rstrip('/')
        threads = config['threads']

        denovo_calls_paths = {}
        denovo_distances_path = {}

        # genotyping software commands
        genotyping_args = config['genotyping']

        forward_reads_list_path = genotyping_args['forward_reads']
        reverse_reads_list_path = genotyping_args['reverse_reads']

        forward_reads_paths = {}
        reverse_reads_paths = {}

        with open(forward_reads_list_path,'r') as forwards_file:
            for line in forwards_file:
                path = line.rstrip() 
                # basename of the FASTQ file
                base = os.path.basename(path)
                # remove '_1.fastq'
                accession = os.path.splitext(base)[0].split('_')[0]
                forward_reads_paths[accession] = path

        with open(reverse_reads_list_path,'r') as reverse_file:
            for line in reverse_file:
                path = line.rstrip() 
                # basename of the FASTQ file
                base = os.path.basename(path)
                # remove '_2.fastq' from basename
                accession = os.path.splitext(base)[0].split('_')[0]
                reverse_reads_paths[accession] = path

        # Get the accessions
        accessions = set(forward_reads_paths.keys()).union(reverse_reads_paths.keys())

        if 'mentalist' in genotyping_args:
            logger.info("Running MentaLiST...")
            mentalist_args = genotyping_args['mentalist']

            assert('output' in mentalist_args['call'] and mentalist_args['call'] is not None),\
                   'Please provide an output path for MentaLiST'
            denovo_calls_paths['MLST'] = mentalist_args['call']['output']

            db_path = "%s/mlst.db" % temp_dir

            # Run any one of the database building mentalist subcommands
            for subcmd in ['build_db','download_pubmlst','download_cgmlst','download_enterobase']:
                if subcmd in mentalist_args:
                    subcmd_options = mentalist_args[subcmd]['options']
                    mentalist_command = ['mentalist',subcmd,'--db %s' % db_path]
                    try:
                        for arg in subcmd_options:
                            mentalist_command.append('--%s %s' % (arg,subcmd_options[arg])) 
                    except:
                        pass

                    if 'flags' in mentalist_args[subcmd]:
                        subcmd_flags = mentalist_args[subcmd]['flags']
                        try:
                            for arg in subcmd_flags:
                                mentalist_command.append('--%s' % arg)
                        except:
                            pass
                    logger.info("Constructing database with command '%s'..." % subcmd)
                    subprocess.call(mentalist_command)
                    logger.info("Finished constructing database.")

            mentalist_calls_paths = []

            for accession in accessions:
                call_path = '%s/%s.calls' % (temp_dir,accession)
                call_command = ['mentalist','call','--db %s' % db_path, '-o %s' % call_path] 

                # Add input reads path to mentalist call command
                if accession not in forward_reads_paths and accession in reverse_reads_paths:
                    call_command.append('-1 %s' % reverse_reads_paths[accession])
                elif accession in forward_reads_paths:
                    call_command.append('-1 %s' % forward_reads_paths[accession])
                    if accession in reverse_reads_paths:
                        call_command.append('-2 %s' % reverse_reads_paths[accession])
                
                call_options = mentalist_args['call']['options']
                for arg in call_options:
                    call_command.append('--%s %s' % (arg,call_options[arg]))

                call_flags = mentalist_args['call']['flags']
                for arg in call_flags:
                    call_command.append('--%s' % call_flags[arg])
                logger.info("Calling MLSTs on accession %s using MentaLiST..." % accession)
                subprocess.call(call_command) 
                logger.info("Finished calling MLSTs on accession %s." % accession)
            
            logger.info("Finished running MentaLiST.")
    
        if 'kwip' in genotyping_args:
            kwip_args = genotyping_args['kwip']

            khmer_command = ['load-into-counting.py -x ']
            khmer_options = genotyping_args['khmer_options']

            try:
                for arg in khmer_options:
                    khmer_command.append( '--%s %s' % (arg,khmer_options[arg]) )
            except:
                pass

            kwip_path = kwip_args['kwip_path']
            kwip_command = [kwip_path]
            kwip_options = kwip_args['kwip_options']
            assert('distance' in kwip_options and kwip_options['distance'] is not None),\
                   'Please provide an output path for kwip'
            denovo_distances_paths['kmer'] = kwip_options['distance']

            try:
                for arg in kwip_options:
                    kwip_command.append('--%s %s' % (arg,kwip_options[arg]))
            except:
                pass

            kwip_flags = kwip_args['kwip_flags']
            try:
                for arg in kwip_flags:
                    kwip_command.append('--%s' % arg)
            except:
                pass

            logger.info("Running khmer (for kWIP)...")
            subprocess.call(khmer_command)
            logger.info("Finished running khmer.")

            logger.info("Running kWIP...")
            subprocess.call(kwip_command)
            logger.info("Finished running kWIP.")
            
        if 'prince' in genotyping_args:
            prince_args = genotyping_args['prince']
            prince_options = prince_args['options']

            assert('target_output' in prince_options and 
                   prince_options['target_output'] is not None),\
                   "Please provide an output path for prince"
            denovo_calls_paths['CNV'] = [prince_options['target_output']]

            prince_command = ['prince']
            try:
                for arg in prince_options:
                    prince_command.append('--%s %s' % (arg,prince_options[arg]))
            except:
                pass

            logger.info("Running PRINCE...")
            subprocess.call(prince_command)
            logger.info("Finished running PRINCE.")

        if 'snippy' in genotyping_args:
            snippy_args = genotyping_args['snippy']
            snippy_options = snippy_args['options']
            snippy_command = ['snippy']
            try:
                for arg in snippy_options:
                    snippy_command.append('--%s %s' % (arg,snippy_options[arg]))
            except:
                pass

            logger.info("Running Snippy...")
            denovo_calls_paths['SNP'] = run_snippy(snippy_command,snippy_options,temp_dir) 
            logger.info("Finished running Snippy.")

        if 'spotyping' in genotyping_args:
            spotyping_args = genotyping_args['spotyping']
            spotyping_path = spotyping_args['path']
            spotyping_command = [spotyping_path] 

            spotyping_options = spotyping_args['options']
            assert('output' in spotyping_options and spotyping_options['output'] is not None),\
                'Please provide an output path for SpoTyping'
            denovo_calls_paths['spoligo'] = spotyping_options['output'] 

            try:
                for arg in spotyping_options:
                    spotyping_command.append('--%s %s' % (arg,spotyping_options[arg]))
            except:
                pass

            spotyping_flags = spotyping_args['flags']
            try:
                for arg in spotyping_flags:
                    spotyping_command.append('--%s' % arg)
            except:
                pass

            spotyping_input = spotyping_args['input']
            try:
                spotyping_command.append(spotyping_args['input'])
            except:
                pass

            logger.info("Running SpoTyping...")
            subprocess.call(spotyping_command)
            logger.info("Finished running SpoTyping.")

        clustering_args = config['clustering']
        # Make sure the configuration file is formatted correctly 
        distance_keys_set = set(clustering_args['distances'].keys())
        genotyping_keys_set = set(clustering_args['genotyping'].keys())
        threshold_keys_set = set(clustering_args['thresholds'].keys())
        fine_clusterings_set = set(clustering_args['fine_clusterings'])
        assert( (distance_keys_set & genotyping_keys_set) == set() ),\
            "'distances' and 'genotyping' have a key in common."
        assert( threshold_keys_set == (distance_keys_set | genotyping_keys_set) ),\
            "Set of keys in thresholds not equal to the set of keys in genotyping and distances."
        assert( fine_clusterings_set <= (distance_keys_set | genotyping_keys_set) ),\
            "A value in 'fine_clusterings' does not appear in 'genotyping' or 'distances'."
        

        # Get genotyping calls
        logger.info('Reading genotyping calls ...')
        read_genotyping_calls = {'SNP': pathogist.io.read_snp_calls,
                                 'MLST': pathogist.io.read_mlst_calls,
                                 'CNV': pathogist.io.read_cnv_calls,
                                 'spoligo': read_spotyping_calls,
                                } 

        calls = {}
        for genotype in clustering_args['calls'].keys():
            calls[genotype] = read_genotyping_calls[genotype](clustering_args['calls'][genotype]) 
        for genotype in denovo_calls_paths:
            calls[genotype] = read_genotype_calls[genotype](denovo_calls_paths)

        # Create distance matrices from calls
        logger.info('Creating distance matrices ...')
        create_genotype_distance = {'SNP': pathogist.distance.create_snp_distance_matrix,
                                    'MLST': pathogist.distance.create_mlst_distance_matrix,
                                    'CNV': pathogist.distance.create_cnv_distance_matrix,
                                    'spoligo': pathogist.distance.create_spoligo_distance_matrix,
                                   }
        for genotype in calls:
            distance_matrix = create_genotype_distance[genotype](calls[genotype])
            distances[genotype] = distance_matrix
            if temp_dir is not None:
                dist_output_path = temp_dir + ("/%s_distance_matrix.tsv" % genotype) 
                logger.info("Saving %s distance matrix at %s..." % (genotype,dist_output_path)) 
                pathogist.io.write_distance_matrix(distance_matrix,dist_output_path) 

        # Read pre-constructed distance matrices
        logger.info('Reading distance matrices...')
        distances = {}
        for genotype in clustering_args['distances'].keys():
            distances[genotype] = pathogist.io.open_distance_file(clustering_args['distances'][genotype])
        for genotype in denovo_distances_path:
            distances[genotype] = pathogist.io.open_distance_file(denovo_distances_path[genotype])

        # Match the distance matrices if need be
        distance_matrix_samples = [frozenset(distances[key].columns.values) for key in distances]

        if (len(set(distance_matrix_samples)) > 1):
            logger.info('Warning: samples differ across the distance matrices.')
            logger.info('Matching distance matrices ...')
            distances = pathogist.distance.match_distance_matrices(distances)
            
        genotypes = distances.keys()
        thresholds = clustering_args['thresholds']
        all_constraints = clustering_args['all_constraints'] 
        output_path = clustering_args['output']
        fine_clusterings = clustering_args['fine_clusterings']
        lp_solver = clustering_args['solver']

        for genotype in genotypes:
            distances[genotype] = distances[genotype].sort_index(axis=0).sort_index(axis=1)

        clusterings = {}
        for genotype in genotypes:
            logger.info('Clustering %s...' % genotype)
            clustering = pathogist.cluster.correlation(distances[genotype],thresholds[genotype],
                                                       all_constraints,solver=lp_solver)     
            clusterings[genotype] = clustering
            if temp_dir is not None:
                cluster_output_path = temp_dir + ("/%s_clustering.tsv" % genotype)
                logger.info("Saving %s clustering at %s..." % (genotype,cluster_output_path)) 
                pathogist.io.output_clustering(clustering,cluster_output_path)
        
        logger.info('Performing consensus clustering...')

        if clustering_args['visualize']:
            consensus_weight_matrix = pathogist.cluster.construct_consensus_weights(clusterings,
                                                                                    distances,
                                                                                    fine_clusterings)
            if temp_dir is not None:
                consensus_weight_output_path = temp_dir + "/consensus_weight_matrix.tsv"
                logger.info("Saving consensus weight matrix at %s..." % consensus_weight_output_path)
                pathogist.io.write_distance_matrix(consensus_weight_matrix,consensus_weight_output_path) 
        else:
            consensus_weight_matrix = None            
        consensus_clustering = pathogist.cluster.consensus(distances,clusterings,fine_clusterings,
                                                           weight_matrix=consensus_weight_matrix,
                                                           solver=lp_solver)
        summary_clustering = pathogist.cluster.summarize_clusterings(consensus_clustering,clusterings)
        logger.info('Writing clusterings to file...')
        pathogist.io.output_clustering(summary_clustering,output_path)
        if clustering_args['visualize']:
            logger.info("Visualizing clusterings...")
            pathogist.visualize.visualize_clusterings(summary_clustering,consensus_weight_matrix)

def correlation(param):
    logger.debug("Opening distance matrix...")
    distance_matrix = pathogist.io.open_distance_file(param.distance_matrix)
    logger.debug("Creating and solving correlation clustering problem ... ")
    clustering = pathogist.cluster.correlation(distance_matrix,param.threshold,param.all_constraints)
    logger.debug("Outputting clustering...")
    pathogist.io.output_clustering(clustering,param.output_path)

def consensus(param):
    logger.info("Getting distance matrices ...")
    distances = collections.OrderedDict()
    with open(param.distance_matrices,'r') as file:
        for line in file:
            name,path = line.rstrip().split('=')
            distances[name] = pathogist.io.open_distance_file(path)

    for cluster1,cluster2 in itertools.combinations(distances.keys(),2):
        columns1 = sorted(list(distances[cluster1].columns.values))
        columns2 = sorted(list(distances[cluster2].columns.values))
        assert( len(columns1) == len(columns2) )
        assert( columns1 == columns2 )
        rows1 = sorted(list(distances[cluster1].index.values))
        rows2 = sorted(list(distances[cluster1].index.values))
        assert( len(rows1) == len(rows2) )
        assert( rows1 == rows2 )

    logger.info("Getting clusterings ...")
    clustering_vectors = collections.OrderedDict()
    clusterings = collections.OrderedDict()
    with open(param.clusterings,'r') as file:
        for line in file:
            cluster,path = line.rstrip().split('=')
            clusterings[cluster] = pathogist.io.open_clustering_file(path)

    for cluster1,cluster2 in itertools.combinations(clusterings.keys(),2):
        columns1 = sorted(list(clusterings[cluster1].columns.values))
        columns2 = sorted(list(clusterings[cluster2].columns.values))
        assert( len(columns1) == len(columns2) )
        assert( columns1 == columns2 )
        rows1 = sorted(list(clusterings[cluster1].index.values))
        rows2 = sorted(list(clusterings[cluster1].index.values))
        assert( len(rows1) == len(rows2) )
        assert( rows1 == rows2 )

    logger.info("Getting other metadata ...")
    fine_clusterings = []
    with open(param.fine_clusterings,'r') as file:
        for line in file:
            fine_clusterings.append( line.rstrip() )
    logger.info("Creating and solving consensus clustering problem ...")
    consensus_clustering = pathogist.cluster.consensus(distances,clusterings,fine_clusterings)
    summary_clustering = pathogist.cluster.summarize_clusterings(consensus_clustering,
                                                                     clusterings)
    logger.info("Writing clusterings to file ...")
    pathogist.io.output_clustering(summary_clustering,param.output_path)

def distance(param):
    logger.info("Creating distance matrix ...")
    distance_matrix = None
    read_genotyping_calls = {'SNP': pathogist.io.read_snp_calls,
                             'MLST': pathogist.io.read_mlst_calls,
                             'CNV': pathogist.io.read_cnv_calls} 
    create_genotype_distance = {'SNP': pathogist.distance.create_snp_distance_matrix,
                                'MLST': pathogist.distance.create_mlst_distance_matrix,
                                'CNV': pathogist.distance.create_cnv_distance_matrix}
    if param.bed == "":								
        calls = read_genotyping_calls[param.data_type](param.calls_path)
    else:
        calls = pathogist.io.read_snp_calls_with_bed(param.calls_path, param.bed )
    distance_matrix = create_genotype_distance[param.data_type](calls)
    if distance_matrix is not None:
        logger.info("Writing distance matrix ...")
        pathogist.io.write_distance_matrix(distance_matrix,param.output_path)
        logger.info("Distance matrix creation complete!")

def visualize(param): 
    if param.data_type == 'distances':
        logger.info("Visualizing distance matrix ...")
        distance_matrix = pathogist.io.open_distance_file(param.input)
        pathogist.visualize.visualize(distance_matrix,param.sample_name)
    elif param.data_type == 'clustering':
        logger.info("Visualing clusterings...")
        summary_clustering = pathogist.io.open_clustering_file(param.input)
        pathogist.visualize.visualize_clusterings(summary_clustering)

def main():
    MAJOR_VERSION = 1
    MINOR_VERSION = 0

    parser = argparse.ArgumentParser(description=('PathOGiST Version %d.%d\n' +
                    'Copyright (C) 2018 Leonid Chindelevitch, Cedric Chauve, William Hsiao')
                    % (MAJOR_VERSION, MINOR_VERSION), formatter_class=argparse.RawTextHelpFormatter)
    parser.add_argument('-ll', '--loglevel', type=str, default="INFO",
                        choices=['DEBUG','INFO','WARNING','ERROR','CRITICAL'],
                        help='Set the logging level')
    subparsers = parser.add_subparsers(dest='subcommand')
    subparsers.required = True

    # command line arguments to run entire pipeline
    all_parser = subparsers.add_parser(name='all', help='run entire PathOGiST pipeline')
    all_parser.add_argument("config", metavar="CONFIG", type=str, 
                     help='path to input configuration file, or path to write a new configuration file')
    all_parser.add_argument("-n","--new_config", action="store_true", default=False,
                            help="write a blank configuration file at path given by CONFIG")

    # Correlation clustering command line arguments
    corr_parser = subparsers.add_parser(name='correlation', help="perform correlation clustering")
    corr_parser.add_argument("distance_matrix", type=str,
                             help="path to the distance matrix file")
    corr_parser.add_argument("threshold", type=float,help="threshold value for correlation")
    corr_parser.add_argument("output_path", type=str, help="path to write cluster output tsv file")
    corr_parser.add_argument("-a", "--all_constraints", action="store_true", default=False,
                             help = "add all constraints to the optimization problem, "
                                  + "not just those with mixed signs.")
    corr_parser.add_argument("-s","--solver",type=str,choices=['cplex','pulp'],default='pulp',
                             help="LP solver interface to use")

    # Consensus clustering command line arguments
    cons_parser = subparsers.add_parser(name='consensus',
                                        help='perform consensus clustering on multiple clusterings')
    cons_parser.add_argument("distance_matrices", type=str,
                             help = "path to file containing paths to distance matrices for different"
                                  + " clusterings")
    cons_parser.add_argument("clusterings", type=str,
                             help = "path to file containing paths to clusterings, represented as"
                                  + " either matrices or lists of clustering assignments")
    cons_parser.add_argument("fine_clusterings", type=str,
                             help = "path to file containing the names of the clusterings which are "
                                  + "the finest")
    cons_parser.add_argument("output_path", type=str, help="path to output tsv file")
    cons_parser.add_argument("-a", "--all_constraints", action="store_true", default=False,
                            help = "add all constraints to the optimization problem, "
                                 + " not just those with mixed signs.")
    cons_parser.add_argument("-s","--solver",type=str,choices=['cplex','pulp'],default='pulp',
                             help="LP solver interface to use")

    # Distance command line arguments
    distance_parser = subparsers.add_parser(name='distance', help = "construct distance matrix from "
                                                                  + "genotyping data")
    distance_parser.add_argument("calls_path", type=str,
                             help = "path to file containing paths to signal calls "
                                  + "(e.g. MLST calls, CNV calls, etc)")
    distance_parser.add_argument("data_type", type=str, choices=['MLST','CNV','SNP'],
                             help = "genotyping data")
    distance_parser.add_argument("output_path", type=str, help="path to output tsv file")
    distance_parser.add_argument("--bed", type=str, default="", required=False, 
                                 help="bed file of unwanted SNP positions in the genome")

    # Visualization command line arguments
    vis_parser = subparsers.add_parser(name='visualize',help="visualize distance matrix or clustering")
    vis_parser.add_argument("input",type=str,
                            help="path to distance matrix or clustering, all in tsv format")
    vis_parser.add_argument("data_type",type=str,choices=['clustering','distances'],
                            help="type of data for the input")

    param = parser.parse_args()

    logging.basicConfig(level=param.loglevel,
                        format='%(asctime)s (%(relativeCreated)d ms) -> %(levelname)s:%(message)s',
                        datefmt='%I:%M:%S %p')

    if param.subcommand == 'all':
        run_all(param)
    elif param.subcommand == 'correlation':
        correlation(param)
    elif param.subcommand == 'consensus':
        consensus(param)
    elif param.subcommand == 'distance':
        distance(param)
    elif param.subcommand == 'visualize':
        visualize(param)

if __name__ == "__main__":
    main()
