#!/usr/bin/env python3
import os
import sys
import subprocess
import resource
import argparse
import logging
import numpy
import itertools
import re
import collections
import pkg_resources
import shutil
import yaml

import pathogist
import pathogist.cluster
import pathogist.io
import pathogist.distance
import pathogist.visualize

logger = logging.getLogger()

def run_all(param):
    '''
    Run the entire PathOGiST pipeline from distance matrix creation to consensus clustering, or create
    a new configuration file.
    '''
    if param.new_config:
        # Copy the default configuration file to whereever the user has specified
        src_path = pkg_resources.resource_filename(__name__,'pathogist/resources/blank_config.yaml') 
        shutil.copyfile(src_path,param.config) 
        print("New configuration file written at %s" % param.config)
    else:
        with open(param.config,'r') as config_stream:
            try:
                config = yaml.load(config_stream) 
            except yaml.YAMLError:
                print(yaml.YAMLError)
                sys.exit(1)

        # genotyping software commands
        genotyping_args = config['genotyping']

        if 'mentalist' in genotyping_args:
            mentalist_args = genotyping_args['mentalist']
            for subcmd in ['build_db','download_pubmlst','download_cgmlst','download_enterobase','call']:
                if subcmd in mentalist_args:
                    subcmd_options = mentalist_args[subcmd]['options']
                    mentalist_command = ['mentalist',subcmd]
                    for arg in subcmd_options:
                        mentalist_command.append('--%s %s' % (arg,subcmd_options[arg])) 
                    subprocess.call(mentalist_command)
            mlst_calls_path = mentalist_args['call']['output']
    
        if 'kwip' in genotyping_args:
            kwip_args = genotyping_args['kwip']
            kwip_path = kwip_args['path']
            kwip_command = [kwip_path]

            kwip_options = kwip_args['options']
            for arg in kwip_options:
                kwip_command.append('--%s %s' % (arg,kwip_options[arg]))

            kwip_flags = kwip_args['flags']
            for arg in kwip_flags:
                kwip_command.append('--%s' % arg)

            subprocess.call(kwip_command)
            
        if 'prince' in genotyping_args:
            prince_args = genotyping_args['prince']
            prince_options = prince_args['options']
            prince_command = ['prince']
            for arg in prince_options:
                prince_command.append('--%s %s' % (arg,prince_options[arg]))
            subprocess.call(prince_command)
            cnv_calls_path = prince_options['target_output']

        if 'snippy' in genotyping_args:
            snippy_args = genotyping_args['snippy']
            snippy_options = snippy_args['options']
            snippy_command = ['snippy']
            for arg in snippy_options:
                snippy_command.append('--%s %s' % (arg,snippy_options[arg]))
            subprocess.call(snippy_command)

        if 'spotyping' in genotyping_args:
            spotyping_args = genotyping_args['spotyping']
            spotyping_path = spotyping_args['path']
            spotyping_command = [spotyping_path] 
            
            spotyping_options = spotyping_args['options']
            for arg in spotyping_options:
                spotyping_command.append('--%s %s' % (arg,spotyping_options[arg]))
            subprocess.call(spotyping_command)

        clustering_args = config['clustering']
        # Make sure the configuration file is formatted correctly 
        distance_keys_set = set(clustering_args['distances'].keys())
        genotyping_keys_set = set(clustering_args['genotyping'].keys())
        threshold_keys_set = set(clustering_args['thresholds'].keys())
        fine_clusterings_set = set(clustering_args['fine_clusterings'])
        assert( (distance_keys_set & genotyping_keys_set) == set() ),\
            "'distances' and 'genotyping' have a key in common."
        assert( threshold_keys_set == (distance_keys_set | genotyping_keys_set) ),\
            "Set of keys in 'thresholds' not equal to the set of keys in 'genotyping' and 'distances'."
        assert( fine_clusterings_set <= (distance_keys_set | genotyping_keys_set) ),\
            "A value in 'fine_clusterings' does not appear in 'genotyping' or 'distances'."
        
        # Determine whether to save temporary files, and which directory to do so
        temp_dir = clustering_args['temp'].rstrip('/')

        # Get genotyping calls
        logger.info('Reading genotyping calls ...')
        read_genotyping_calls = {'SNP': pathogist.io.read_snp_calls,
                                 'MLST': pathogist.io.read_mlst_calls,
                                 'CNV': pathogist.io.read_cnv_calls,
                                 'spoligo': read_spotyping_calls,
                                } 
        calls = {}
        for genotype in clustering_args['calls'].keys():
            calls[genotype] = read_genotyping_calls[genotype](clustering_args['calls'][genotype]) 
        # Create distance matrices from calls
        logger.info('Creating distance matrices ...')
        create_genotype_distance = {'SNP': pathogist.distance.create_snp_distance_matrix,
                                    'MLST': pathogist.distance.create_mlst_distance_matrix,
                                    'CNV': pathogist.distance.create_cnv_distance_matrix,
                                    'spoligo': pathogist.distance.create_spoligo_distance_matrix,
                                   }
        distances = {}
        for genotype in calls:
            distance_matrix = create_genotype_distance[genotype](calls[genotype])
            distances[genotype] = distance_matrix
            if temp_dir is not None:
                dist_output_path = temp_dir + ("/%s_distance_matrix.tsv" % genotype) 
                logger.info("Saving %s distance matrix at %s..." % (genotype,dist_output_path)) 
                pathogist.io.write_distance_matrix(distance_matrix,dist_output_path) 

        # Read pre-constructed distance matrices
        logger.info('Reading distance matrices...')
        for genotype in clustering_args['distances'].keys():
            distances[genotype] = pathogist.io.open_distance_file(clustering_args['distances'][genotype]
        # Match the distance matrices if need be
        distance_matrix_samples = [frozenset(distances[key].columns.values) for key in distances]

        if (len(set(distance_matrix_samples)) > 1):
            logger.info('Warning: samples differ across the distance matrices.')
            logger.info('Matching distance matrices ...')
            distances = pathogist.distance.match_distance_matrices(distances)
            
        # dummy variables to make life easier
        genotypes = distances.keys()
        thresholds = clustering_args['thresholds']
        all_constraints = clustering_args['all_constraints'] 
        output_path = clustering_args['output']
        fine_clusterings = clustering_args['fine_clusterings']
        lp_solver = clustering_args['solver']

        for genotype in genotypes:
            distances[genotype] = distances[genotype].sort_index(axis=0).sort_index(axis=1)

        clusterings = {}
        for genotype in genotypes:
            logger.info('Clustering %s...' % genotype)
            clustering = pathogist.cluster.correlation(distances[genotype],thresholds[genotype],
                                                       all_constraints,solver=lp_solver)     
            clusterings[genotype] = clustering
            if temp_dir is not None:
                cluster_output_path = temp_dir + ("/%s_clustering.tsv" % genotype)
                logger.info("Saving %s clustering at %s..." % (genotype,cluster_output_path)) 
                pathogist.io.output_clustering(clustering,cluster_output_path)
        
        logger.info('Performing consensus clustering...')

        if param.visualize:
            consensus_weight_matrix = pathogist.cluster.construct_consensus_weights(clusterings,
                                                                                    distances,
                                                                                    fine_clusterings)
            if temp_dir is not None:
                consensus_weight_output_path = temp_dir + "/consensus_weight_matrix.tsv"
                logger.info("Saving consensus weight matrix at %s..." % consensus_weight_output_path)
                pathogist.io.write_distance_matrix(consensus_weight_matrix,consensus_weight_output_path) 
        else:
            consensus_weight_matrix = None            
        consensus_clustering = pathogist.cluster.consensus(distances,clusterings,fine_clusterings,
                                                           weight_matrix=consensus_weight_matrix,
                                                           solver=lp_solver)
        summary_clustering = pathogist.cluster.summarize_clusterings(consensus_clustering,clusterings)
        logger.info('Writing clusterings to file...')
        pathogist.io.output_clustering(summary_clustering,output_path)
        if param.visualize:
            logger.info("Visualizing clusterings...")
            pathogist.visualize.visualize_clusterings(summary_clustering,consensus_weight_matrix)

def correlation(param):
    logger.debug("Opening distance matrix...")
    distance_matrix = pathogist.io.open_distance_file(param.distance_matrix)
    logger.debug("Creating and solving correlation clustering problem ... ")
    clustering = pathogist.cluster.correlation(distance_matrix,param.threshold,param.all_constraints)
    logger.debug("Outputting clustering...")
    pathogist.io.output_clustering(clustering,param.output_path)

def consensus(param):
    logger.info("Getting distance matrices ...")
    distances = collections.OrderedDict()
    with open(param.distance_matrices,'r') as file:
        for line in file:
            name,path = line.rstrip().split('=')
            distances[name] = pathogist.io.open_distance_file(path)

    for cluster1,cluster2 in itertools.combinations(distances.keys(),2):
        columns1 = sorted(list(distances[cluster1].columns.values))
        columns2 = sorted(list(distances[cluster2].columns.values))
        assert( len(columns1) == len(columns2) )
        assert( columns1 == columns2 )
        rows1 = sorted(list(distances[cluster1].index.values))
        rows2 = sorted(list(distances[cluster1].index.values))
        assert( len(rows1) == len(rows2) )
        assert( rows1 == rows2 )

    logger.info("Getting clusterings ...")
    clustering_vectors = collections.OrderedDict()
    clusterings = collections.OrderedDict()
    with open(param.clusterings,'r') as file:
        for line in file:
            cluster,path = line.rstrip().split('=')
            clusterings[cluster] = pathogist.io.open_clustering_file(path)

    for cluster1,cluster2 in itertools.combinations(clusterings.keys(),2):
        columns1 = sorted(list(clusterings[cluster1].columns.values))
        columns2 = sorted(list(clusterings[cluster2].columns.values))
        assert( len(columns1) == len(columns2) )
        assert( columns1 == columns2 )
        rows1 = sorted(list(clusterings[cluster1].index.values))
        rows2 = sorted(list(clusterings[cluster1].index.values))
        assert( len(rows1) == len(rows2) )
        assert( rows1 == rows2 )

    logger.info("Getting other metadata ...")
    fine_clusterings = []
    with open(param.fine_clusterings,'r') as file:
        for line in file:
            fine_clusterings.append( line.rstrip() )
    logger.info("Creating and solving consensus clustering problem ...")
    consensus_clustering = pathogist.cluster.consensus(distances,clusterings,fine_clusterings)
    summary_clustering = pathogist.cluster.summarize_clusterings(consensus_clustering,
                                                                     clusterings)
    logger.info("Writing clusterings to file ...")
    pathogist.io.output_clustering(summary_clustering,param.output_path)

def distance(param):
    logger.info("Creating distance matrix ...")
    distance_matrix = None
    read_genotyping_calls = {'SNP': pathogist.io.read_snp_calls,
                             'MLST': pathogist.io.read_mlst_calls,
                             'CNV': pathogist.io.read_cnv_calls} 
    create_genotype_distance = {'SNP': pathogist.distance.create_snp_distance_matrix,
                                'MLST': pathogist.distance.create_mlst_distance_matrix,
                                'CNV': pathogist.distance.create_cnv_distance_matrix}
    if param.bed == "":								
        calls = read_genotyping_calls[param.data_type](param.calls_path)
    else:
        calls = pathogist.io.read_snp_calls_with_bed(param.calls_path, param.bed )
    distance_matrix = create_genotype_distance[param.data_type](calls)
    if distance_matrix is not None:
        logger.info("Writing distance matrix ...")
        pathogist.io.write_distance_matrix(distance_matrix,param.output_path)
        logger.info("Distance matrix creation complete!")

def visualize(param): 
    if param.data_type == 'distances':
        logger.info("Visualizing distance matrix ...")
        distance_matrix = pathogist.io.open_distance_file(param.input)
        pathogist.visualize.visualize(distance_matrix,param.sample_name)
    elif param.data_type == 'clustering':
        logger.info("Visualing clusterings...")
        summary_clustering = pathogist.io.open_clustering_file(param.input)
        pathogist.visualize.visualize_clusterings(summary_clustering)

def main():
    MAJOR_VERSION = 1
    MINOR_VERSION = 0

    parser = argparse.ArgumentParser(description=('PathOGiST Version %d.%d\n' +
                    'Copyright (C) 2018 Leonid Chindelevitch, Cedric Chauve, William Hsiao')
                    % (MAJOR_VERSION, MINOR_VERSION), formatter_class=argparse.RawTextHelpFormatter)
    parser.add_argument('-ll', '--loglevel', type=str, default="INFO",
                        choices=['DEBUG','INFO','WARNING','ERROR','CRITICAL'],
                        help='Set the logging level')
    subparsers = parser.add_subparsers(dest='subcommand')
    subparsers.required = True

    # command line arguments to run entire pipeline
    all_parser = subparsers.add_parser(name='all', help='run entire PathOGiST pipeline')
    all_parser.add_argument("config", metavar="CONFIG", type=str, 
                     help='path to input configuration file, or path to write a new configuration file')
    all_parser.add_argument("-n","--new_config", action="store_true", default=False,
                            help="write a blank configuration file at path given by CONFIG")
    all_parser.add_argument('-v','--visualize',action="store_true",default=False,
                            help='Visualize the clusterings.')

    # Correlation clustering command line arguments
    corr_parser = subparsers.add_parser(name='correlation', help="perform correlation clustering")
    corr_parser.add_argument("distance_matrix", type=str,
                             help="path to the distance matrix file")
    corr_parser.add_argument("threshold", type=float,help="threshold value for correlation")
    corr_parser.add_argument("output_path", type=str, help="path to write cluster output tsv file")
    corr_parser.add_argument("-a", "--all_constraints", action="store_true", default=False,
                             help = "add all constraints to the optimization problem, "
                                  + "not just those with mixed signs.")
    corr_parser.add_argument("-s","--solver",type=str,choices=['cplex','pulp'],default='pulp',
                             help="LP solver interface to use")

    # Consensus clustering command line arguments
    cons_parser = subparsers.add_parser(name='consensus',
                                        help='perform consensus clustering on multiple clusterings')
    cons_parser.add_argument("distance_matrices", type=str,
                             help = "path to file containing paths to distance matrices for different"
                                  + " clusterings")
    cons_parser.add_argument("clusterings", type=str,
                             help = "path to file containing paths to clusterings, represented as"
                                  + " either matrices or lists of clustering assignments")
    cons_parser.add_argument("fine_clusterings", type=str,
                             help = "path to file containing the names of the clusterings which are "
                                  + "the finest")
    cons_parser.add_argument("output_path", type=str, help="path to output tsv file")
    cons_parser.add_argument("-a", "--all_constraints", action="store_true", default=False,
                            help = "add all constraints to the optimization problem, "
                                 + " not just those with mixed signs.")
    cons_parser.add_argument("-s","--solver",type=str,choices=['cplex','pulp'],default='pulp',
                             help="LP solver interface to use")

    # Distance command line arguments
    distance_parser = subparsers.add_parser(name='distance', help = "construct distance matrix from "
                                                                  + "genotyping data")
    distance_parser.add_argument("calls_path", type=str,
                             help = "path to file containing paths to signal calls "
                                  + "(e.g. MLST calls, CNV calls, etc)")
    distance_parser.add_argument("data_type", type=str, choices=['MLST','CNV','SNP'],
                             help = "genotyping data")
    distance_parser.add_argument("output_path", type=str, help="path to output tsv file")
    distance_parser.add_argument("--bed", type=str, default="", required=False, 
                                 help="bed file of unwanted SNP positions in the genome")

    # Visualization command line arguments
    vis_parser = subparsers.add_parser(name='visualize',help="visualize distance matrix or clustering")
    vis_parser.add_argument("input",type=str,
                            help="path to distance matrix or clustering, all in tsv format")
    vis_parser.add_argument("data_type",type=str,choices=['clustering','distances'],
                            help="type of data for the input")

    param = parser.parse_args()

    logging.basicConfig(level=param.loglevel,
                        format='%(asctime)s (%(relativeCreated)d ms) -> %(levelname)s:%(message)s',
                        datefmt='%I:%M:%S %p')

    if param.subcommand == 'all':
        run_all(param)
    elif param.subcommand == 'correlation':
        correlation(param)
    elif param.subcommand == 'consensus':
        consensus(param)
    elif param.subcommand == 'distance':
        distance(param)
    elif param.subcommand == 'visualize':
        visualize(param)

if __name__ == "__main__":
    main()
